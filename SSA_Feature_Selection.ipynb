{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7s0Dbu-cZbS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def Evaluate(ACTUAL, PREDICTED):\n",
        "    un = np.unique(ACTUAL)\n",
        "    tp = np.zeros(len(un))\n",
        "    tn = np.zeros(len(un))\n",
        "    fp = np.zeros(len(un))\n",
        "    fn = np.zeros(len(un))\n",
        "\n",
        "    for i, cls in enumerate(un):\n",
        "        idx = (ACTUAL == cls)\n",
        "        p = np.sum(ACTUAL == cls)\n",
        "        n = np.sum(ACTUAL != cls)\n",
        "        N = p + n\n",
        "\n",
        "        tp[i] = np.sum((ACTUAL[idx] == PREDICTED[idx]))\n",
        "        tn[i] = np.sum((ACTUAL[~idx] == PREDICTED[~idx]))\n",
        "        fp[i] = n - tn[i]\n",
        "        fn[i] = p - tp[i]\n",
        "\n",
        "    tp_rate = tp / (tp + fn)\n",
        "    tn_rate = tn / (tn + fp)\n",
        "    accuracy = (tp + tn) / N\n",
        "    sensitivity = tp_rate\n",
        "    specificity = tn_rate\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = sensitivity\n",
        "    f_measure = 2 * ((precision * recall) / (precision + recall))\n",
        "    gmax = np.sqrt(tp_rate * tn_rate)\n",
        "\n",
        "    sensitivity[np.isnan(sensitivity)] = 0\n",
        "    precision[np.isnan(precision)] = 0\n",
        "    recall[np.isnan(recall)] = 0\n",
        "    f_measure[np.isnan(f_measure)] = 0\n",
        "    gmax[np.isnan(gmax)] = 0\n",
        "\n",
        "    EVAL = np.array([max(accuracy), max(sensitivity), max(specificity), max(precision), max(recall), max(f_measure), max(gmax)])\n",
        "    cf = np.vstack((tp, tn, fp, fn))\n",
        "\n",
        "    return EVAL, cf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def fitness(dat, lab, sl):\n",
        "    ind = np.where(sl)[0]\n",
        "    data_subset = dat[:, ind]\n",
        "\n",
        "    md = RandomForestClassifier()\n",
        "    md.fit(data_subset, lab)\n",
        "    LL = md.predict(data_subset)\n",
        "    accuracy = accuracy_score(lab, LL)\n",
        "    ft = 1 - accuracy\n",
        "\n",
        "    return ft\n"
      ],
      "metadata": {
        "id": "1j6D_gVqcoX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def levy(n, m, beta):\n",
        "    num = np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2)\n",
        "    den = np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2)\n",
        "    sigma_u = (num / den) ** (1 / beta)\n",
        "\n",
        "    u = np.random.normal(0, sigma_u ** 2, (n, m))\n",
        "    v = np.random.normal(0, 1, (n, m))\n",
        "    z = u / (np.abs(v) ** (1 / beta))\n",
        "\n",
        "    return z\n"
      ],
      "metadata": {
        "id": "f2_ZmSSZcoMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "file_path = \"/content/diabetes.csv\"\n",
        "\n",
        "file_name = os.path.basename(file_path)\n",
        "file_dir = os.path.dirname(file_path)\n",
        "\n",
        "X = pd.read_csv(file_path)\n",
        "\n",
        "data2 = X.iloc[:, :-1].values\n",
        "class_label = X.iloc[:, -1].values\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "data1 = imputer.fit_transform(data2)\n"
      ],
      "metadata": {
        "id": "uD9LMhOBd432"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "FSL, FSU = 0, 1\n",
        "D = data1.shape[1]\n",
        "FS = np.zeros((10, D))\n",
        "fit = np.zeros(10)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    FS[i, :] = FSL + np.random.uniform(0, 1, D) * (FSU - FSL)\n",
        "    try:\n",
        "        fit[i] = fitness(data1, class_label, FS[i, :])\n",
        "    except:\n",
        "        fit[i] = 1\n",
        "        continue\n",
        "\n",
        "ind = np.where(fit == np.min(fit))[0]\n",
        "FSnew = FS[ind, :]\n",
        "pdp = 0.1\n",
        "row, V, S, cd, CL, hg, sf = 1.204, 5.25, 0.0154, 0.6, 0.7, 1, 18\n",
        "Gc = 1.9\n",
        "D1 = 1 / (2 * row * V ** 2 * S * cd)\n",
        "L = 1 / (2 * row * V ** 2 * S * CL)\n",
        "tanpi = D1 / L\n",
        "dg = hg / (tanpi * sf)\n",
        "aa = np.random.randint(1, len(ind))\n",
        "iter, maxiter = 1, 4\n",
        "\n",
        "while iter < maxiter:\n",
        "    for i in range(10):\n",
        "        if np.random.rand() >= pdp:\n",
        "            FS[i, :] = np.round(FS[i, :] + (dg * Gc * np.abs(FSnew[i, :] - FS[i, :])))\n",
        "        else:\n",
        "            FS[i, :] = FSL + np.random.uniform(0, 1, D) * (FSU - FSL)\n",
        "        Fh = FS\n",
        "        # print(FS)\n",
        "        fit1 = fitness(data1, class_label, FS[i, :])\n",
        "        ind1 = np.where(fit1 == np.min(fit1))[0]\n",
        "        FSnew1 = FS[ind1, :]\n",
        "\n",
        "        if np.random.rand() > pdp:\n",
        "            FS[i, :] = np.round(FS[i, :] + (dg * Gc * abs(FSnew[aa, :] - FS[i, :])))\n",
        "        else:\n",
        "            FS[i, :] = FSL + np.random.uniform(0, 1, D) * (FSU - FSL)\n",
        "        Fa = FS\n",
        "        fit2 = fitness(data1, class_label, FS[i, :])\n",
        "        ind2 = np.where(fit2 == np.min(fit2))[0]\n",
        "        FSnew2 = FS[ind2, :]\n",
        "\n",
        "    Sc = np.sqrt(np.sum(np.abs(Fh - Fa)) ** 2)\n",
        "    Smin = (10 * np.exp(-6)) / (365) ** (iter / (maxiter / 2.5))\n",
        "\n",
        "    if Sc < Smin:\n",
        "        season = 'summer'\n",
        "        for i in range(10):\n",
        "            FS[i, :] = FSL + levy(1, D, 1.5) * (FSU - FSL)\n",
        "    else:\n",
        "        season = 'winter'\n",
        "        break\n",
        "\n",
        "    fit3 = fitness(data1, class_label, FS[i, :])\n",
        "    ind3 = np.where(fit3 == np.min(fit3))[0]\n",
        "    final = np.array([Fh[ind1, :], Fa[ind2, :], FS[ind3, :]])\n",
        "    final = np.abs(final.round())\n",
        "    for i in range(final.shape[0]):\n",
        "        fitt = fitness(data1, class_label, final[i, :])\n",
        "\n",
        "    best = np.min(fitt)\n",
        "    inn = np.argmin(fitt)\n",
        "    bestfeat = final[inn, :]\n",
        "    pdp = best\n",
        "\n",
        "    iter += 1\n"
      ],
      "metadata": {
        "id": "3Dd2mHtqgao8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import random\n",
        "\n",
        "\n",
        "sel = np.where(bestfeat[-1])[0]\n",
        "print('Selected Features')\n",
        "print(sel)\n",
        "\n",
        "dataA = data2[:, sel]  # Assuming data2 is your test data\n",
        "\n",
        "p = 0.75  # Proportion of rows to select for training\n",
        "N = dataA.shape[0]  # Total number of rows\n",
        "tf = np.full(N, False)  # Create logical index vector\n",
        "tf[:round(p*N)] = True\n",
        "np.random.shuffle(tf)  # Randomize order\n",
        "\n",
        "dataTraining = dataA[tf, :]\n",
        "labeltraining = class_label[tf]\n",
        "\n",
        "dataTesting = dataA[~tf, :]\n",
        "labeltesting = class_label[~tf]\n",
        "\n",
        "print('Training feature size:', len(dataTraining))\n",
        "print('Testing feature size:', len(dataTesting))\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svt = SVC()\n",
        "svt.fit(dataTraining, labeltraining)\n",
        "out1 = svt.predict(dataTesting)\n",
        "\n",
        "# K-Nearest Neighbors (KNN)\n",
        "mdl = KNeighborsClassifier()\n",
        "mdl.fit(dataTraining, labeltraining)\n",
        "out2 = mdl.predict(dataTesting)\n",
        "\n",
        "# Random Forest (RF)\n",
        "mdl = RandomForestClassifier()\n",
        "mdl.fit(dataTraining, labeltraining)\n",
        "out3 = mdl.predict(dataTesting)\n",
        "\n",
        "# Evaluation\n",
        "def evaluate(y_true, y_pred):\n",
        "    cf = confusion_matrix(y_true, y_pred)\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    accuracy = report['accuracy']\n",
        "    precision = report['macro avg']['precision']\n",
        "    recall = report['macro avg']['recall']\n",
        "    f1_score = report['macro avg']['f1-score']\n",
        "    return accuracy, precision, recall, f1_score\n",
        "\n",
        "eval1 = evaluate(labeltesting, out1)\n",
        "eval2 = evaluate(labeltesting, out2)\n",
        "eval3 = evaluate(labeltesting, out3)\n",
        "\n",
        "print(\"SVM Performance:\")\n",
        "print(\"Accuracy:\", eval1[0])\n",
        "print(\"Precision:\", eval1[1])\n",
        "print(\"Recall:\", eval1[2])\n",
        "print(\"F1-Score:\", eval1[3])\n",
        "\n",
        "print(\"KNN Performance:\")\n",
        "print(\"Accuracy:\", eval2[0])\n",
        "print(\"Precision:\", eval2[1])\n",
        "print(\"Recall:\", eval2[2])\n",
        "print(\"F1-Score:\", eval2[3])\n",
        "\n",
        "print(\"Random Forest Performance:\")\n",
        "print(\"Accuracy:\", eval3[0])\n",
        "print(\"Precision:\", eval3[1])\n",
        "print(\"Recall:\", eval3[2])\n",
        "print(\"F1-Score:\", eval3[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z4ipaQi0e3_",
        "outputId": "ece19189-f400-424f-d475-4eb34023d084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features\n",
            "[0 1 2 6]\n",
            "Training feature size: 576\n",
            "Testing feature size: 192\n",
            "SVM Performance:\n",
            "Accuracy: 0.734375\n",
            "Precision: 0.75557461406518\n",
            "Recall: 0.6570257611241218\n",
            "F1-Score: 0.6616798535051653\n",
            "KNN Performance:\n",
            "Accuracy: 0.7135416666666666\n",
            "Precision: 0.6996254097081317\n",
            "Recall: 0.6497658079625293\n",
            "F1-Score: 0.6551611533814452\n",
            "Random Forest Performance:\n",
            "Accuracy: 0.71875\n",
            "Precision: 0.7118421052631578\n",
            "Recall: 0.6508196721311476\n",
            "F1-Score: 0.656005308560053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "saUrilDEcxxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYVfrrfrO87F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}